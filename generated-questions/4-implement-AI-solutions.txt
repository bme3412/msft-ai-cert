Implement AI Solutions Responsibly
Q1. Content Moderation

A company is deploying a chatbot that answers medical questions. They want to ensure responses containing self-harm or sexual content are automatically flagged before reaching users. Which Azure service should they use?

A. Azure AI Search
B. Azure AI Content Safety
C. Azure AI Speech
D. Azure Monitor

✅ Answer: B – Content Safety detects harmful text/images and blocks or flags outputs.

Q2. Content Filters

Which categories can Azure AI Content Safety detect in text and images?

A. Only profanity and hate speech
B. Violence, sexual content, self-harm, hate/harassment
C. Token overuse and latency issues
D. Financial fraud and phishing

✅ Answer: B – Content Safety covers violence, sexual, self-harm, and hate/harassment.

Q3. Responsible AI Insights

You’ve deployed GPT-4 in Azure. Leadership asks you to provide a dashboard showing how many outputs were flagged as harmful over the past month. Which feature should you use?

A. Responsible AI Insights
B. Azure Key Vault
C. Diagnostics Logs
D. Azure DevOps

✅ Answer: A – Responsible AI Insights provides dashboards for moderation and safety monitoring.

Q4. Preventing Jailbreak Attacks

Which of the following is the most effective way to prevent prompt injection and jailbreak attempts?

A. Store API keys in Azure Key Vault
B. Enable prompt shields and blocklists in Azure AI Studio
C. Deploy services via containers
D. Add usage quotas

✅ Answer: B – Prompt shields + blocklists are designed to detect and block jailbreak/prompt injection attempts.

Q5. Blocklists

A bank wants to prevent its AI assistant from mentioning competitor names under any circumstances. Which feature should you configure?

A. Quota limits
B. Custom blocklists
C. Application Insights
D. Batch inference

✅ Answer: B – Blocklists prevent disallowed terms or phrases in AI responses.

Q6. Governance Framework

Which element would not typically be part of a Responsible AI governance framework?

A. Compliance and ethics reviews
B. Human oversight for high-risk cases
C. Content filtering and moderation
D. GPU quota allocation for training

✅ Answer: D – GPU quota management is operational, not part of governance/RAI.

Q7. Human Oversight

A customer support AI is deployed with content safety filters, but management requires a process for humans to review high-severity flagged outputs before release. This aligns with which RAI principle?

A. Fairness
B. Accountability
C. Transparency
D. Inclusiveness

✅ Answer: B – Accountability requires human oversight and responsibility for AI decisions.

Q8. Transparency

A financial services chatbot must tell customers: “This response was generated by AI and should not be considered financial advice.” Which principle does this reflect?

A. Fairness
B. Reliability
C. Transparency
D. Privacy

✅ Answer: C – Transparency ensures users know when they are interacting with AI.

Q9. Trick Question — Content Moderation vs. Governance

A healthcare provider needs to comply with HIPAA regulations while using GPT-4 for medical note summarization. Which two controls are most relevant?

A. Azure AI Content Safety and profanity filters
B. Governance framework including compliance reviews and human oversight
C. Azure Monitor dashboards
D. Application Insights

✅ Answer: B – Governance ensures compliance with laws like HIPAA, plus oversight for accountability.

Q10. Trick Question — Prevention vs. Monitoring

An e-commerce chatbot was tricked into giving discount codes using a jailbreak prompt. Which preventive control would have best reduced this risk?

A. Budget alerts in Azure Cost Management
B. Prompt shields with blocklists for restricted outputs
C. Monitoring token consumption
D. Using Managed Identity for authentication

✅ Answer: B – Prompt shields and blocklists directly stop jailbreak attacks.